{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tweepy and NLTK to Analyze Tweets about Netflix #Punisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, I intend to stream twitter data about The Punisher using Python's Tweepy library. I will then flatten the tweets, load them to Pandas, and analyze using techniques including, but not limited to, NLTK.\n",
    "\n",
    "\n",
    "\n",
    "A few modules used are checked in to my GitHub page (flatten_tweets, slistener)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Stream Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import libraries and setup matplotlib to run inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tweepy import OAuthHandler, API, Stream\n",
    "from slistener import SListener\n",
    "from flatten_tweets import flatten_tweets, check_word_in_tweet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load credentials from a JSON.  Since these keys are personal, they are kept in a file that is not checked in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cred():\n",
    "    with open('twitter_credentials.json') as cred_data:\n",
    "        info = json.load(cred_data)\n",
    "        consumer_key = info['CONSUMER_KEY']\n",
    "        consumer_secret = info['CONSUMER_SECRET']\n",
    "        access_key = info['ACCESS_KEY']\n",
    "        access_secret = info['ACCESS_SECRET']\n",
    "    \n",
    "    return consumer_key, consumer_secret, access_key, access_secret\n",
    "\n",
    "consumer_key, consumer_secret, access_token, access_token_secret = load_cred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorization and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up words to track (in this case just #Punisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_to_track = ['#Punisher']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SListener module is checked in to my GitHub page.  Here, instantiate SLIstener, Stream, and begin collecting tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listen = SListener(api)\n",
    "stream = Stream(auth, listen)\n",
    "stream.filter(track = keywords_to_track)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Intake and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load JSONs. These were collected for a few hours over a couple of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 tweets being analyzed.\n"
     ]
    }
   ],
   "source": [
    "tweet_list = []\n",
    "\n",
    "for file in glob.glob(\"streamer* - Copy.json\"):\n",
    "    with open(file, 'r') as tweet_data:\n",
    "        tweets_json = filter(None, tweet_data.read().split(\"\\n\"))\n",
    "        \n",
    "    for tweet in tweets_json:\n",
    "        tweet_obj = json.loads(tweet)\n",
    "        tweet_list.append(tweet_obj)\n",
    "        \n",
    "print(\"{0} tweets being analyzed.\".format(len(tweet_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten tweets, loading into Pandas DataFrame, print first 5 rows of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    RT @Randomgamerma: My reaction to season 2 of ...\n",
      "1    Someone give @benbarnes his goddamn Oscar omg ...\n",
      "2                       #Punisher punish her real good\n",
      "3    RT @venuspriestess: @benbarnes screams of terr...\n",
      "4    The Punisher season 2 on @netflix is getting r...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tweets = flatten_tweets(tweet_list)\n",
    "ds_tweets = pd.DataFrame(tweets)\n",
    "print(ds_tweets['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of #Punisher tweets: 1.0\n"
     ]
    }
   ],
   "source": [
    "#punish = ds_tweets['text'].str.contains('Punisher',case = False)\n",
    "punish = check_word_in_tweet('#Punisher', ds_tweets)\n",
    "print(\"Proportion of #Punisher tweets:\", np.sum(punish) / ds_tweets.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A proportion of 1.0 shows that every tweet contains #Punisher somewhere, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
